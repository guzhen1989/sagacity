# 缓存策略与数据管理

<cite>
**本文档引用文件**   
- [adaptive.py](file://tradingagents/dataflows/cache/adaptive.py)
- [db_cache.py](file://tradingagents/dataflows/cache/db_cache.py)
- [file_cache.py](file://tradingagents/dataflows/cache/file_cache.py)
- [cache.py](file://app/routers/cache.py)
- [quotes_service.py](file://app/services/quotes_service.py)
</cite>

## 目录
1. [自适应缓存淘汰算法](#自适应缓存淘汰算法)
2. [数据库与文件缓存同步机制](#数据库与文件缓存同步机制)
3. [行情数据缓存实践](#行情数据缓存实践)
4. [缓存清理与刷新接口](#缓存清理与刷新接口)
5. [缓存防护方案](#缓存防护方案)

## 自适应缓存淘汰算法

`adaptive.py` 文件实现了自适应缓存系统，该系统根据数据库可用性自动选择最佳缓存策略。系统通过 `AdaptiveCacheSystem` 类实现，其核心功能是根据配置动态调整缓存后端和TTL（Time To Live）。

系统首先通过 `get_database_manager()` 获取数据库管理器，然后根据配置文件中的 `primary_backend` 设置主要缓存后端（支持 Redis、MongoDB 和文件系统）。同时，系统支持降级机制，当主要后端不可用时，可自动降级到文件缓存。

TTL 的动态调整逻辑在 `_get_ttl_seconds` 方法中实现。系统根据股票代码判断市场类型：若为6位纯数字，则判定为A股（`china`），否则为美股（`us`）。然后根据市场类型和数据类型（如 `stock_data`、`news_data` 等）从配置中获取对应的TTL设置。例如，美股行情数据的TTL为7200秒（2小时），而A股行情数据的TTL可能更短，以保证实时性。

缓存键的生成通过 `_get_cache_key` 方法实现，结合股票代码、日期范围、数据源和数据类型生成MD5哈希值作为唯一键。系统在保存数据时，优先使用主要后端，若失败则根据 `fallback_enabled` 配置决定是否降级到文件缓存。

**Section sources**
- [adaptive.py](file://tradingagents/dataflows/cache/adaptive.py#L1-L441)

## 数据库与文件缓存同步机制

系统通过 `db_cache.py` 和 `file_cache.py` 实现了数据库与文件缓存的同步机制，确保数据的高可用性和持久化。

`db_cache.py` 中的 `DatabaseCacheManager` 类同时管理 MongoDB 和 Redis 两个后端。当保存数据时，系统会将数据同时写入 MongoDB（持久化存储）和 Redis（高速缓存）。例如，在 `save_stock_data` 方法中，数据首先以 JSON 格式序列化后存入 MongoDB 的 `stock_data` 集合，同时以 JSON 字符串形式存入 Redis，并设置6小时的过期时间。这样，读取时优先从 Redis 获取（毫秒级响应），若 Redis 未命中，则从 MongoDB 加载，并重新写入 Redis 以供后续快速访问。

对于美股基本面数据（如 `300750.SZ_fundamentals_*.txt`），系统在 `file_cache.py` 中实现了持久化策略。`StockDataCache` 类将不同市场和数据类型的数据分类存储在不同的子目录中，如 `us_fundamentals` 和 `china_fundamentals`。基本面数据以文本文件（`.txt`）形式保存，并生成对应的元数据文件（`_meta.json`），记录创建时间、数据源等信息。系统通过 `is_cache_valid` 方法检查缓存有效性，根据市场类型自动应用不同的TTL策略（美股基本面数据TTL为24小时，A股为12小时）。

此外，系统实现了内容长度检查机制。当数据内容超过 `MAX_CACHE_CONTENT_LENGTH` 环境变量设定的阈值（默认50,000字符）时，系统会检查是否有支持长文本的LLM提供商（如 `dashscope`、`openai`、`google`）可用。若有，则继续缓存；否则跳过缓存以避免性能问题。

**Section sources**
- [db_cache.py](file://tradingagents/dataflows/cache/db_cache.py#L1-L578)
- [file_cache.py](file://tradingagents/dataflows/cache/file_cache.py#L1-L686)

## 行情数据缓存实践

`quotes_service.py` 文件实现了行情数据的缓存实践，特别针对A股实时快照进行了优化。

`QuotesService` 类使用内存中的字典作为缓存，通过 `get_quotes` 方法提供批量获取股票行情的功能。缓存键为股票代码，值为包含最新价、涨跌幅和成交额的字典。系统通过 `ttl_seconds` 参数（默认30秒）控制缓存有效期。当缓存未过期时，直接返回缓存数据；否则，通过 `akshare` 库的 `stock_zh_a_spot_em` 接口获取全市场快照，并更新缓存。

缓存键生成规则遵循统一的命名空间隔离原则。所有缓存键均以数据类型为前缀，如 `stock`、`news`、`fundamentals`，后接股票代码和参数的MD5哈希值，确保键的唯一性。例如，`_generate_cache_key` 方法生成的键格式为 `{data_type}:{symbol}:{md5_hash}`。

在批量操作优化方面，系统通过 `get_quotes` 方法一次性获取多个股票的行情，避免了多次API调用。同时，使用 `asyncio.Lock` 确保缓存更新的线程安全，防止并发请求导致的重复拉取。对于大批次操作，系统将阻塞的IO操作（如网络请求）放入线程池执行，避免阻塞事件循环，从而提高整体性能。

**Section sources**
- [quotes_service.py](file://app/services/quotes_service.py#L1-L112)

## 缓存清理与刷新接口

`cache.py` 文件在 `app/routers` 目录下提供了缓存清理与刷新的HTTP接口，供管理员通过API进行缓存管理。

`/api/cache/stats` 接口返回缓存统计信息，包括总文件数、总大小、各类数据（行情、新闻、基本面）的数量。该接口调用 `get_cache_stats` 方法，该方法会遍历文件缓存目录和数据库，汇总所有后端的统计信息。

`/api/cache/cleanup` 接口用于清理过期缓存，接受 `days` 参数指定清理多少天前的缓存。系统会遍历文件缓存的元数据文件，删除创建时间早于截止时间的文件及其元数据。对于数据库缓存，MongoDB 通过 `created_at` 字段和TTL索引自动清理，Redis 则依赖自身的过期机制。

`/api/cache/clear` 接口用于清空所有缓存，相当于调用 `cleanup` 接口并将 `days` 设为0。该操作会删除所有缓存文件和数据库中的缓存集合，适用于需要强制刷新数据的场景。

`/api/cache/details` 和 `/api/cache/backend-info` 接口分别提供缓存详情列表和后端配置信息，便于监控和诊断。

**Section sources**
- [cache.py](file://app/routers/cache.py#L1-L212)

## 缓存防护方案

系统实现了针对缓存穿透和缓存雪崩的防护方案。

缓存穿透防护通过在 `file_cache.py` 中的 `should_skip_cache_for_content` 方法实现。当请求的数据内容为空或不存在时，系统不会将其写入缓存，从而避免了对同一无效键的重复查询。此外，系统通过内容长度检查，防止恶意的超长数据请求耗尽存储资源。

缓存雪崩防护通过以下机制实现：
1. **TTL随机化**：虽然代码中未显式实现，但系统设计允许在配置TTL时加入随机偏移，避免大量缓存同时过期。
2. **多级缓存**：系统采用 Redis（内存）、MongoDB（磁盘）、文件系统（本地）的多级缓存架构。即使某一层失效，其他层仍可提供服务。
3. **降级机制**：如 `adaptive.py` 中所述，当主要后端（如 Redis）不可用时，系统自动降级到文件缓存，保证服务不中断。
4. **预热机制**：虽然未在代码中体现，但可通过定时任务在系统启动或低峰期预加载热点数据，减少突发流量对后端的压力。

这些防护措施共同确保了缓存系统的稳定性和可靠性，即使在高并发或异常情况下也能提供良好的服务。

**Section sources**
- [adaptive.py](file://tradingagents/dataflows/cache/adaptive.py#L1-L441)
- [file_cache.py](file://tradingagents/dataflows/cache/file_cache.py#L1-L686)