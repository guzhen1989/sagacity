# 数据库缓存配置

<cite>
**本文档引用的文件**   
- [mongodb_cache_adapter.py](file://tradingagents/dataflows/cache/mongodb_cache_adapter.py)
- [db_cache.py](file://tradingagents/dataflows/cache/db_cache.py)
- [CACHE_CONFIGURATION.md](file://docs/configuration/CACHE_CONFIGURATION.md)
- [enable_mongodb_cache.py](file://scripts/enable_mongodb_cache.py)
- [init_mongodb_indexes.py](file://scripts/setup/init_mongodb_indexes.py)
- [optimize_mongodb_indexes.py](file://scripts/maintenance/optimize_mongodb_indexes.py)
- [cache.py](file://app/routers/cache.py)
</cite>

## 目录
1. [简介](#简介)
2. [MongoDB缓存配置](#mongodb缓存配置)
3. [缓存数据结构设计](#缓存数据结构设计)
4. [索引优化策略](#索引优化策略)
5. [缓存一致性维护](#缓存一致性维护)
6. [性能监控与容量规划](#性能监控与容量规划)
7. [缓存管理接口](#缓存管理接口)
8. [总结](#总结)

## 简介
本文档详细介绍了如何将MongoDB配置为系统的二级缓存存储。系统采用分层缓存架构，支持文件、Redis和MongoDB等多种缓存后端，并可根据配置自动选择最优的缓存策略。MongoDB作为持久化缓存层，提供了高性能的数据访问和可靠的持久化存储能力。

## MongoDB缓存配置
系统通过环境变量和配置文件来控制MongoDB缓存的启用和配置。主要配置项包括缓存策略、MongoDB连接信息等。

### 启用MongoDB缓存
要启用MongoDB缓存，需要设置`TA_CACHE_STRATEGY`环境变量为`integrated`。系统提供了多种配置方式：

#### 环境变量配置
```bash
export TA_CACHE_STRATEGY=integrated
export MONGODB_URL=mongodb://admin:tradingagents123@localhost:27018
export REDIS_URL=redis://:tradingagents123@localhost:6380
```

#### .env文件配置
在项目根目录的`.env`文件中添加以下配置：
```env
# 缓存策略配置
TA_CACHE_STRATEGY=integrated

# MongoDB连接配置
MONGODB_URL=mongodb://admin:tradingagents123@localhost:27018

# Redis连接配置（可选）
REDIS_URL=redis://:tradingagents123@localhost:6380
```

### 自动降级机制
系统具备智能的自动降级机制，当主要缓存后端不可用时，会自动切换到备用方案：
- 优先尝试使用Redis + MongoDB组合（高性能模式）
- 如果Redis不可用，则使用MongoDB + 文件缓存（持久化模式）
- 如果MongoDB也不可用，则降级到文件缓存（标准模式）

这种设计确保了系统的高可用性，即使数据库服务暂时中断，系统仍能正常运行。

**Section sources**
- [CACHE_CONFIGURATION.md](file://docs/configuration/CACHE_CONFIGURATION.md#集成缓存配置)
- [enable_mongodb_cache.py](file://scripts/enable_mongodb_cache.py#L16-L62)

## 缓存数据结构设计
MongoDB中的缓存数据采用规范化的文档结构设计，包含业务数据和元数据两部分。

### 文档结构
缓存文档包含以下主要字段：

| 字段名 | 类型 | 说明 |
|-------|------|------|
| `_id` | string | 缓存键，由数据类型、股票代码和参数生成的MD5哈希值 |
| `symbol` | string | 股票代码 |
| `market_type` | string | 市场类型（china/us） |
| `data_type` | string | 数据类型（stock_data/news_data/fundamentals_data） |
| `start_date` | string | 开始日期 |
| `end_date` | string | 结束日期 |
| `data_source` | string | 数据源 |
| `data` | string | 序列化的数据内容（JSON格式） |
| `data_format` | string | 数据格式标识 |
| `created_at` | datetime | 创建时间 |
| `updated_at` | datetime | 更新时间 |

### 元数据字段
系统在每个缓存文档中都包含了丰富的元数据信息，用于追踪数据来源和生命周期：

- **创建时间** (`created_at`): 记录缓存项的创建时间戳，用于TTL管理和过期清理
- **更新时间** (`updated_at`): 记录最后一次更新的时间，用于缓存一致性检查
- **数据源标识** (`data_source`): 标识数据来源（tushare/akshare/baostock等），支持多数据源优先级查询
- **市场类型** (`market_type`): 区分A股和美股等不同市场的数据，便于针对性处理

这种设计使得系统能够实现精细化的缓存管理，如按数据源优先级查询、按市场类型设置不同的缓存策略等。

**Section sources**
- [db_cache.py](file://tradingagents/dataflows/cache/db_cache.py#L217-L227)
- [mongodb_cache_adapter.py](file://tradingagents/dataflows/cache/mongodb_cache_adapter.py#L225-L226)

## 索引优化策略
为了确保缓存查询的高性能，系统为关键字段创建了优化的复合索引。

### 主要索引设计
系统为`stock_data`、`news_data`和`fundamentals_data`三个主要集合创建了针对性的索引：

```python
# 股票数据集合索引
stock_collection.create_index([
    ("symbol", 1),
    ("data_source", 1),
    ("start_date", 1),
    ("end_date", 1)
])
stock_collection.create_index([("created_at", 1)])

# 新闻数据集合索引
news_collection.create_index([
    ("symbol", 1),
    ("data_source", 1),
    ("date_range", 1)
])
news_collection.create_index([("created_at", 1)])

# 基本面数据集合索引
fundamentals_collection.create_index([
    ("symbol", 1),
    ("data_source", 1),
    ("analysis_date", 1)
])
fundamentals_collection.create_index([("created_at", 1)])
```

### 索引创建脚本
系统提供了自动化脚本来初始化和优化MongoDB索引：

```python
# 初始化索引脚本
def ensure_indexes():
    uri = build_mongo_uri()
    client = MongoClient(uri)
    db = client[dbname]

    # 为stock_basic_info集合创建索引
    sbi = db["stock_basic_info"]
    sbi.create_index([("code", ASCENDING), ("source", ASCENDING)], unique=True, name="uniq_code_source")
    sbi.create_index([("code", ASCENDING)], name="idx_code")
    sbi.create_index([("source", ASCENDING)], name="idx_source")
    # ... 其他索引
```

这些索引遵循ESR（Equality-Sort-Range）原则，确保查询性能最优。例如，对于股票数据查询，先匹配等值字段（symbol、data_source），再按日期范围查询。

**Section sources**
- [db_cache.py](file://tradingagents/dataflows/cache/db_cache.py#L136-L173)
- [init_mongodb_indexes.py](file://scripts/setup/init_mongodb_indexes.py#L38-L76)
- [optimize_mongodb_indexes.py](file://scripts/maintenance/optimize_mongodb_indexes.py#L53-L90)

## 缓存一致性维护
系统采用主动失效和智能查询相结合的策略来维护缓存一致性。

### 数据源优先级查询
系统实现了基于配置的数据源优先级查询机制，确保获取最新、最准确的数据：

```python
def _get_data_source_priority(self, symbol: str) -> list:
    """
    获取数据源优先级顺序
    返回按优先级排序的数据源列表，例如: ["tushare", "akshare", "baostock"]
    """
    # 1. 识别市场分类
    market = StockUtils.identify_stock_market(symbol)
    
    # 2. 从数据库读取配置
    config_data = config_collection.find_one(
        {"is_active": True},
        sort=[("version", -1)]
    )
    
    # 3. 过滤启用的数据源并按优先级排序
    enabled.sort(key=lambda x: x.get('priority', 0), reverse=True)
    result = [ds.get('type', '').lower() for ds in enabled if ds.get('type')]
    
    return result if result else ['tushare', 'akshare', 'baostock']
```

### 缓存失效策略
系统通过以下机制维护缓存一致性：

1. **TTL机制**：为不同类型的数据设置不同的过期时间
   - 股票数据：6小时
   - 新闻数据：24小时
   - 基本面数据：24小时

2. **主动清理**：定期清理过期缓存
```python
def clear_old_cache(self, max_age_days: int = 7):
    """清理过期缓存"""
    cutoff_time = datetime.now(ZoneInfo(get_timezone_name())) - timedelta(days=max_age_days)
    # 清理MongoDB中的过期记录
    collection.delete_many({"created_at": {"$lt": cutoff_time}})
```

3. **写时更新**：当新数据写入时，直接替换旧的缓存文档，确保数据最新

这种组合策略既保证了数据的及时性，又避免了频繁的缓存失效带来的性能开销。

**Section sources**
- [mongodb_cache_adapter.py](file://tradingagents/dataflows/cache/mongodb_cache_adapter.py#L81-L158)
- [db_cache.py](file://tradingagents/dataflows/cache/db_cache.py#L538-L556)

## 性能监控与容量规划
系统提供了完善的性能监控和容量规划支持，帮助管理员了解缓存使用情况并进行合理规划。

### 性能监控指标
系统通过`get_cache_stats()`方法提供详细的缓存统计信息：

```python
def get_cache_stats(self) -> Dict[str, Any]:
    """获取缓存统计信息"""
    stats = {
        'total_files': 0,
        'stock_data_count': 0,
        'news_count': 0,
        'fundamentals_count': 0,
        'total_size': 0,  # 字节
        'total_size_mb': 0,  # MB
        'backend_info': {
            "mongodb": {"available": self.mongodb_db is not None, "collections": {}},
            "redis": {"available": self.redis_client is not None, "keys": 0, "memory_usage": "N/A"}
        }
    }
    return stats
```

关键监控指标包括：
- **缓存命中率**：通过统计缓存查询成功率来计算
- **查询延迟**：记录每次查询的执行时间
- **存储使用量**：监控MongoDB集合的大小和索引占用空间
- **连接状态**：监控MongoDB和Redis的连接健康状况

### 容量规划建议
基于系统运行经验和性能测试，提出以下容量规划建议：

1. **存储容量**：
   - 预计每只股票每天的历史数据约占用1-2KB
   - 1000只股票一年的数据量约为360-720MB
   - 建议预留2-3倍的空间用于索引和增长

2. **索引优化**：
   - 定期运行`optimize_mongodb_indexes.py`脚本优化索引
   - 监控慢查询日志，及时添加缺失的索引
   - 索引大小不应超过数据大小的50%

3. **性能预期**：
   - 优化后查询响应时间应小于10ms
   - 单实例支持每秒1000+次缓存查询
   - 建议使用Redis作为一级缓存，MongoDB作为二级缓存

4. **运维建议**：
   - 每月执行一次索引优化
   - 监控MongoDB的慢查询日志
   - 定期备份缓存数据

**Section sources**
- [db_cache.py](file://tradingagents/dataflows/cache/db_cache.py#L473-L536)
- [optimize_mongodb_indexes.py](file://scripts/maintenance/optimize_mongodb_indexes.py#L160-L183)

## 缓存管理接口
系统提供了REST API接口用于缓存的管理和监控。

### API端点
| 端点 | 方法 | 功能 |
|------|------|------|
| `/api/cache/stats` | GET | 获取缓存统计信息 |
| `/api/cache/cleanup` | DELETE | 清理过期缓存 |
| `/api/cache/clear` | DELETE | 清空所有缓存 |
| `/api/cache/details` | GET | 获取缓存详情列表 |
| `/api/cache/backend-info` | GET | 获取缓存后端信息 |

### 使用示例
```python
# 获取缓存统计
GET /api/cache/stats
Response:
{
    "data": {
        "totalFiles": 1500,
        "totalSize": 104857600,
        "maxSize": 1073741824,
        "stockDataCount": 1000,
        "newsDataCount": 300,
        "analysisDataCount": 200
    }
}

# 清理7天前的缓存
DELETE /api/cache/cleanup?days=7
```

这些API接口为系统管理员提供了便捷的缓存管理工具，可以通过前端界面或命令行工具进行操作。

**Section sources**
- [cache.py](file://app/routers/cache.py#L18-L212)

## 总结
本系统通过将MongoDB配置为二级缓存存储，实现了高性能、高可用的缓存架构。系统支持灵活的缓存策略配置，可通过环境变量轻松启用MongoDB缓存。缓存数据采用规范化的文档结构设计，包含丰富的元数据信息，支持精细化的缓存管理。

通过合理的索引优化策略，系统能够确保缓存查询的高性能。自动降级机制保证了系统的高可用性，即使数据库服务中断，系统仍能正常运行。完善的性能监控和容量规划建议帮助管理员更好地维护系统。

建议在生产环境中启用MongoDB缓存，并定期执行索引优化，以获得最佳的系统性能。